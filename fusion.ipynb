{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-10T11:03:19.334857Z","iopub.status.busy":"2024-07-10T11:03:19.334124Z","iopub.status.idle":"2024-07-10T11:03:32.077549Z","shell.execute_reply":"2024-07-10T11:03:32.076473Z","shell.execute_reply.started":"2024-07-10T11:03:19.334825Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-10 11:03:22.197593: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-10 11:03:22.197692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-10 11:03:22.331058: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import pathlib\n","import os\n","import glob as gb\n","import cv2\n","import PIL\n","import seaborn as sns\n","import tensorflow as tf\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n","from tensorflow.keras.utils import to_categorical\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg19 import VGG19\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow import keras\n","from keras.models import Model"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T11:03:45.205430Z","iopub.status.busy":"2024-07-10T11:03:45.204340Z","iopub.status.idle":"2024-07-10T11:03:45.209252Z","shell.execute_reply":"2024-07-10T11:03:45.208405Z","shell.execute_reply.started":"2024-07-10T11:03:45.205398Z"},"trusted":true},"outputs":[],"source":["trainpath = '/Users/amanmaurya/Desktop/Rice Leaf Disease Image Classification/dataset/train'\n","testpath = '/Users/amanmaurya/Desktop/Rice Leaf Disease Image Classification/dataset/test'"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Image Processing"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T11:03:52.025422Z","iopub.status.busy":"2024-07-10T11:03:52.024476Z","iopub.status.idle":"2024-07-10T11:04:24.213202Z","shell.execute_reply":"2024-07-10T11:04:24.212310Z","shell.execute_reply.started":"2024-07-10T11:03:52.025391Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Entering the folder: Tungro\n","Number of images in the folder: 1108\n","Entering the folder: BacterialBlight\n","Number of images in the folder: 1384\n","Entering the folder: Blast\n","Number of images in the folder: 1240\n","Entering the folder: BrownSpot\n","Number of images in the folder: 1400\n","Entering to the folder name: Tungro\n","Number of images in the folder is 200\n","Entering to the folder name: BacterialBlight\n","Number of images in the folder is 200\n","Entering to the folder name: Blast\n","Number of images in the folder is 200\n","Entering to the folder name: BrownSpot\n","Number of images in the folder is 200\n","(5132, 224, 224, 3)\n","********************\n","(5132,)\n","********************\n","(800, 224, 224, 3)\n","(800,)\n","Num GPUs Available: 2\n"]}],"source":["# Image Processing - Training Data\n","new_size = 224\n","train_images = []\n","train_labels = []\n","class_disease = {'BacterialBlight': 0, 'Blast': 1, 'BrownSpot': 2, 'Tungro': 3}\n","\n","for i in os.listdir(trainpath):\n","    if i in class_disease:\n","        print(\"Entering the folder:\", i)\n","        files = gb.glob(pathname=str(trainpath + '/' + i + '/*.jpg')) + gb.glob(pathname=str(trainpath + '/' + i + '/*.JPG'))\n","        print(\"Number of images in the folder:\", len(files))\n","        for j in files:\n","            image_raw = cv2.imread(j)\n","            image = cv2.cvtColor(image_raw, cv2.COLOR_BGR2RGB)\n","            resize_image = cv2.resize(image, (new_size, new_size))\n","            train_images.append(list(resize_image))\n","            train_labels.append(class_disease[i])\n","\n","# Image Processing - Testing Data\n","new_size = 224\n","test_images = []\n","test_labels = []\n","\n","for i in os.listdir(testpath):\n","    if i in class_disease:\n","        print(\"Entering to the folder name:\", i)\n","        files = gb.glob(pathname=str(testpath + '/' + i + '/*.jpg')) + gb.glob(pathname=str(testpath + '/' + i + '/*.JPG'))\n","        print(\"Number of images in the folder is\", len(files))\n","        for j in files:\n","            image_raw = cv2.imread(j)\n","            image = cv2.cvtColor(image_raw, cv2.COLOR_BGR2RGB)\n","            resize_image = cv2.resize(image, (new_size, new_size))\n","            test_images.append(list(resize_image))\n","            test_labels.append(class_disease[i])\n","\n","def list_to_array_train(train_images, train_labels):\n","    return np.array(train_images), np.array(train_labels)\n","\n","X_train, y_train = list_to_array_train(train_images, train_labels)\n","\n","def list_to_array_test(test_images, test_labels):\n","    return np.array(test_images), np.array(test_labels)\n","\n","X_test, y_test = list_to_array_test(test_images, test_labels)\n","\n","print(X_train.shape)\n","print(\"*\" * 20)\n","print(y_train.shape)\n","print(\"*\" * 20)\n","print(X_test.shape)\n","print(y_test.shape)\n","\n","def keras_to_categorical(y_train, y_test):\n","    return to_categorical(y_train), to_categorical(y_test)\n","\n","y_train1 = y_train\n","y_test1 = y_test\n","y_train, y_test = keras_to_categorical(y_train, y_test)\n","\n","y_train1.shape, y_test1.shape\n","\n","def convert_one_hot_to_categorical(one_hot_labels):\n","    return np.argmax(one_hot_labels, axis=1)\n","\n","gpus = tf.config.list_physical_devices('GPU')\n","print(f\"Num GPUs Available: {len(gpus)}\")\n","\n","if len(gpus) < 2:\n","    print(\"Not enough GPUs available, ensure your environment is configured correctly\")\n","else:\n","    for gpu in gpus:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","    strategy = tf.distribute.MirroredStrategy()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T11:04:34.719708Z","iopub.status.busy":"2024-07-10T11:04:34.718963Z","iopub.status.idle":"2024-07-10T11:04:34.724076Z","shell.execute_reply":"2024-07-10T11:04:34.723143Z","shell.execute_reply.started":"2024-07-10T11:04:34.719676Z"},"trusted":true},"outputs":[],"source":["# Function to convert one-hot encoded labels to categorical labels\n","def convert_one_hot_to_categorical(one_hot_labels):\n","    return np.argmax(one_hot_labels, axis=1)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T11:04:35.794416Z","iopub.status.busy":"2024-07-10T11:04:35.793798Z","iopub.status.idle":"2024-07-10T11:04:35.804726Z","shell.execute_reply":"2024-07-10T11:04:35.803735Z","shell.execute_reply.started":"2024-07-10T11:04:35.794382Z"},"trusted":true},"outputs":[],"source":["# Deep Feature Extraction - VGG19\n","def model_vgg19():\n","    VGG_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    for layer in VGG_model.layers:\n","        layer.trainable = False\n","    feature = GlobalAveragePooling2D()(VGG_model.output)\n","    output = Model(inputs=VGG_model.input, outputs=feature)\n","    return output\n","\n","# Deep Feature Extraction - ResNet50\n","def model_resnet50():\n","    Resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    for layer in Resnet_model.layers:\n","        layer.trainable = False\n","    feature = GlobalAveragePooling2D()(Resnet_model.output)\n","    output = Model(inputs=Resnet_model.input, outputs=feature)\n","    return output\n","\n","# Deep Feature Extraction - EfficientNet\n","def model_effnet():\n","    Effnet_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    for layer in Effnet_model.layers:\n","        layer.trainable = False\n","    feature = GlobalAveragePooling2D()(Effnet_model.output)\n","    output = Model(inputs=Effnet_model.input, outputs=feature)\n","    return output\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T11:04:41.715665Z","iopub.status.busy":"2024-07-10T11:04:41.714685Z","iopub.status.idle":"2024-07-10T11:11:37.016508Z","shell.execute_reply":"2024-07-10T11:11:37.015688Z","shell.execute_reply.started":"2024-07-10T11:04:41.715623Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/skimage/feature/texture.py:353: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n","  warnings.warn(\n"]}],"source":["# LBP\n","\n","from skimage.feature import local_binary_pattern\n","from skimage.color import rgb2gray\n","from tqdm import tqdm\n","\n","# Parameters for LBP\n","radius = 3\n","n_points = 8 * radius\n","\n","def compute_lbp_features(image):\n","    if image.ndim == 3 and image.shape[2] == 3:  # Check if the image is RGB\n","        gray_image = rgb2gray(image)\n","    elif image.ndim == 2:  # If the image is already grayscale\n","        gray_image = image\n","    else:\n","        raise ValueError(f\"Unexpected image shape: {image.shape}\")\n","    \n","    lbp = local_binary_pattern(gray_image, n_points, radius, method='uniform')\n","    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n","    hist = hist.astype(\"float\")\n","    hist /= (hist.sum() + 1e-6)  # Normalize the histogram\n","    return hist\n","\n","def extract_lbp_features(X):\n","    return np.array([compute_lbp_features(img) for img in X])\n","\n","train_feature_lbp = extract_lbp_features(X_train)\n","test_feature_lbp = extract_lbp_features(X_test)\n"]},{"cell_type":"markdown","metadata":{},"source":["# VGG19 + LBP + Random Forest Classifier"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T11:13:09.862956Z","iopub.status.busy":"2024-07-10T11:13:09.862216Z","iopub.status.idle":"2024-07-10T11:17:43.893526Z","shell.execute_reply":"2024-07-10T11:17:43.892612Z","shell.execute_reply.started":"2024-07-10T11:13:09.862925Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:   0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  10%|█         | 1/10 [00:27<04:05, 27.27s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 1 - Accuracy: 0.97625000, Recall: 0.97625000, Precision: 0.99874372, F1 Score: 0.98702370, AUC: 0.98791667\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  20%|██        | 2/10 [00:54<03:39, 27.44s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 2 - Accuracy: 0.96000000, Recall: 0.96000000, Precision: 1.00000000, F1 Score: 0.97900157, AUC: 0.98000000\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  30%|███       | 3/10 [01:22<03:11, 27.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 3 - Accuracy: 0.95500000, Recall: 0.95500000, Precision: 1.00000000, F1 Score: 0.97637441, AUC: 0.97750000\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  40%|████      | 4/10 [01:49<02:44, 27.39s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 4 - Accuracy: 0.97750000, Recall: 0.97750000, Precision: 1.00000000, F1 Score: 0.98827683, AUC: 0.98875000\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  50%|█████     | 5/10 [02:16<02:16, 27.39s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 5 - Accuracy: 0.96125000, Recall: 0.96125000, Precision: 1.00000000, F1 Score: 0.97986393, AUC: 0.98062500\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  60%|██████    | 6/10 [02:44<01:49, 27.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 6 - Accuracy: 0.96250000, Recall: 0.96250000, Precision: 1.00000000, F1 Score: 0.98047069, AUC: 0.98125000\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  70%|███████   | 7/10 [03:11<01:22, 27.34s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 7 - Accuracy: 0.97500000, Recall: 0.97500000, Precision: 0.99874372, F1 Score: 0.98639713, AUC: 0.98729167\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  80%|████████  | 8/10 [03:39<00:54, 27.41s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 8 - Accuracy: 0.97125000, Recall: 0.97125000, Precision: 1.00000000, F1 Score: 0.98517523, AUC: 0.98562500\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP:  90%|█████████ | 9/10 [04:06<00:27, 27.41s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 9 - Accuracy: 0.96125000, Recall: 0.96125000, Precision: 1.00000000, F1 Score: 0.97970702, AUC: 0.98062500\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating VGG16+LBP: 100%|██████████| 10/10 [04:33<00:00, 27.37s/it]"]},{"name":"stdout","output_type":"stream","text":["Run 10 - Accuracy: 0.96500000, Recall: 0.96500000, Precision: 0.99747475, F1 Score: 0.98061215, AUC: 0.98208333\n","\n","Average Metrics:\n","Accuracy: 0.96650000 (std: 0.00747496)\n","Recall: 0.96650000 (std: 0.00747496)\n","Precision: 0.99949622 (std: 0.00083639)\n","F1: 0.98229026 (std: 0.00384622)\n","Auc: 0.98316667 (std: 0.00369732)\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","Metrics results saved to 'VGG16+VGG19+RF.xlsx'\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","def train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test):\n","    with strategy.scope():  \n","        model_FE_19 = model_vgg19()\n","        model_FE_19.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","        train_feature_19 = model_FE_19.predict(X_train)\n","        test_feature_19 = model_FE_19.predict(X_test)\n","        \n","        final_train = np.hstack((train_feature_19, train_feature_lbp))\n","        final_test = np.hstack((test_feature_19, test_feature_lbp))\n","\n","        rf = RandomForestClassifier()\n","        rf = rf.fit(final_train, y_train)\n","        test_pred = rf.predict(final_test)\n","\n","        accuracy = accuracy_score(y_test, test_pred)\n","        recall = recall_score(y_test, test_pred, average='weighted')\n","        precision = precision_score(y_test, test_pred, average='weighted')\n","        f1 = f1_score(y_test, test_pred, average='weighted')\n","        auc = roc_auc_score(y_test, test_pred, multi_class='ovr', average='weighted')\n","\n","        return accuracy, recall, precision, f1, auc\n","\n","num_runs = 10\n","results = {'accuracy': [], 'recall': [], 'precision': [], 'f1': [], 'auc': []}\n","\n","for i in tqdm(range(num_runs), desc=\"Evaluating VGG19+LBP: \"):\n","    accuracy, recall, precision, f1, auc = train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test)\n","    results['accuracy'].append(accuracy)\n","    results['recall'].append(recall)\n","    results['precision'].append(precision)\n","    results['f1'].append(f1)\n","    results['auc'].append(auc)\n","    print(f\"Run {i+1} - Accuracy: {accuracy:.8f}, Recall: {recall:.8f}, Precision: {precision:.8f}, F1 Score: {f1:.8f}, AUC: {auc:.8f}\")\n","\n","# Calculate average metrics\n","average_metrics = {metric: np.mean(values) for metric, values in results.items()}\n","std_metrics = {metric: np.std(values) for metric, values in results.items()}\n","\n","# Print average metrics\n","print(\"\\nAverage Metrics:\")\n","for metric, value in average_metrics.items():\n","    print(f\"{metric.capitalize()}: {value:.8f} (std: {std_metrics[metric]:.8f})\")\n","\n","# Convert results to a pandas DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Save results to an Excel file\n","output_file = 'VGG19+LBP+RF.xlsx'\n","results_df.to_excel(output_file, index_label='Run')\n","\n","print(f\"\\nMetrics results saved to '{output_file}'\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# VGG19 + VGG19 + Decision Tree Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T11:18:23.975528Z","iopub.status.busy":"2024-07-10T11:18:23.974638Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step\n","Run 1 - Accuracy: 0.93000000, Recall: 0.93000000, Precision: 0.93051467, F1 Score: 0.92931978, AUC: 0.95333333\n","\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step\n"]}],"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","def train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test):\n","    with strategy.scope():  \n","        model_FE_19 = model_vgg19()\n","        model_FE_19.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","        train_feature_19 = model_FE_19.predict(X_train)\n","        test_feature_19 = model_FE_19.predict(X_test)\n","        \n","        final_train = np.hstack((train_feature_19, train_feature_lbp))\n","        final_test = np.hstack((test_feature_19, test_feature_lbp))\n","\n","        # Define and train Decision Tree Classifier\n","        dt = DecisionTreeClassifier()\n","        dt.fit(final_train, y_train)\n","        test_pred = dt.predict(final_test)\n","\n","        # Calculate evaluation metrics\n","        accuracy = accuracy_score(y_test, test_pred)\n","        recall = recall_score(y_test, test_pred, average='weighted')\n","        precision = precision_score(y_test, test_pred, average='weighted')\n","        f1 = f1_score(y_test, test_pred, average='weighted')\n","        auc = roc_auc_score(y_test, test_pred, multi_class='ovr', average='weighted')\n","\n","        return accuracy, recall, precision, f1, auc\n","\n","# Perform multiple runs and store the results\n","num_runs = 10\n","results = {'accuracy': [], 'recall': [], 'precision': [], 'f1': [], 'auc': []}\n","\n","for i in range(num_runs):\n","    accuracy, recall, precision, f1, auc = train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test)\n","    results['accuracy'].append(accuracy)\n","    results['recall'].append(recall)\n","    results['precision'].append(precision)\n","    results['f1'].append(f1)\n","    results['auc'].append(auc)\n","    print(f\"Run {i+1} - Accuracy: {accuracy:.8f}, Recall: {recall:.8f}, Precision: {precision:.8f}, F1 Score: {f1:.8f}, AUC: {auc:.8f}\")\n","\n","# Compute average and standard deviation for each metric\n","average_metrics = {metric: np.mean(values) for metric, values in results.items()}\n","std_metrics = {metric: np.std(values) for metric, values in results.items()}\n","\n","print(\"\\nAverage Metrics:\")\n","for metric, value in average_metrics.items():\n","    print(f\"{metric.capitalize()}: {value:.8f} (std: {std_metrics[metric]:.8f})\")\n","\n","# Convert results to a pandas DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Save results to an Excel file\n","output_file = 'VGG19+LBP+DTC.xlsx'\n","results_df.to_excel(output_file, index_label='Run')\n","\n","print(f\"\\nMetrics results saved to '{output_file}'\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# VGG19 + VGG19 + KNN Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","def train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test, num):\n","    with strategy.scope():  \n","        model_FE_19 = model_vgg19()\n","        model_FE_19.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","        train_feature_19 = model_FE_19.predict(X_train)\n","        test_feature_19 = model_FE_19.predict(X_test)\n","        \n","        final_train = np.hstack((train_feature_19, train_feature_lbp))\n","        final_test = np.hstack((test_feature_19, test_feature_lbp))\n","\n","        # Define and train KNN Classifier\n","        knn = KNeighborsClassifier(n_neighbors=num)\n","        knn.fit(final_train, y_train)\n","        test_pred = knn.predict(final_test)\n","\n","        # Calculate evaluation metrics\n","        accuracy = accuracy_score(y_test, test_pred)\n","        recall = recall_score(y_test, test_pred, average='weighted')\n","        precision = precision_score(y_test, test_pred, average='weighted')\n","        f1 = f1_score(y_test, test_pred, average='weighted')\n","        auc = roc_auc_score(y_test, test_pred, multi_class='ovr', average='weighted')\n","\n","        return accuracy, recall, precision, f1, auc\n","\n","# Perform multiple runs and store the results\n","num_runs = 10\n","results = {'accuracy': [], 'recall': [], 'precision': [], 'f1': [], 'auc': []}\n","num = 5\n","\n","for i in range(num_runs):\n","    accuracy, recall, precision, f1, auc = train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test, num)\n","    results['accuracy'].append(accuracy)\n","    results['recall'].append(recall)\n","    results['precision'].append(precision)\n","    results['f1'].append(f1)\n","    results['auc'].append(auc)\n","    print(f\"Run {i+1} - Accuracy: {accuracy:.8f}, Recall: {recall:.8f}, Precision: {precision:.8f}, F1 Score: {f1:.8f}, AUC: {auc:.8f}\")\n","    num = num+1\n","\n","# Compute average and standard deviation for each metric\n","average_metrics = {metric: np.mean(values) for metric, values in results.items()}\n","std_metrics = {metric: np.std(values) for metric, values in results.items()}\n","\n","print(\"\\nAverage Metrics:\")\n","for metric, value in average_metrics.items():\n","    print(f\"{metric.capitalize()}: {value:.8f} (std: {std_metrics[metric]:.8f})\")\n","\n","# Convert results to a pandas DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Save results to an Excel file\n","output_file = 'VGG19+LBP+KNN.xlsx'\n","results_df.to_excel(output_file, index_label='Run')\n","\n","print(f\"\\nMetrics results saved to '{output_file}'\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# VGG16 + LBP + SVM Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.svm import SVC\n","\n","def train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test):\n","    with strategy.scope():  \n","        y_train_cat = convert_one_hot_to_categorical(y_train)\n","        y_test_cat = convert_one_hot_to_categorical(y_test)\n","        \n","        model_FE_19 = model_vgg19()\n","        model_FE_19.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","        train_feature_19 = model_FE_19.predict(X_train)\n","        test_feature_19 = model_FE_19.predict(X_test)\n","        \n","        final_train = np.hstack((train_feature_19, train_feature_lbp))\n","        final_test = np.hstack((test_feature_19, test_feature_lbp))\n","\n","        # Define and train SVM Classifier\n","        svm = SVC(probability=True)\n","        svm.fit(final_train, y_train_cat)\n","        test_pred = svm.predict(final_test)\n","        test_pred_proba = svm.predict_proba(final_test)\n","\n","        # Calculate evaluation metrics\n","        accuracy = accuracy_score(y_test_cat, test_pred)\n","        recall = recall_score(y_test_cat, test_pred, average='weighted')\n","        precision = precision_score(y_test_cat, test_pred, average='weighted')\n","        f1 = f1_score(y_test_cat, test_pred, average='weighted')\n","        auc = roc_auc_score(y_test_cat, test_pred_proba, multi_class='ovr', average='weighted')\n","\n","        return accuracy, recall, precision, f1, auc\n","\n","# Perform multiple runs and store the results\n","num_runs = 10\n","results = {'accuracy': [], 'recall': [], 'precision': [], 'f1': [], 'auc': []}\n","\n","for i in range(num_runs):\n","    accuracy, recall, precision, f1, auc = train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test)\n","    results['accuracy'].append(accuracy)\n","    results['recall'].append(recall)\n","    results['precision'].append(precision)\n","    results['f1'].append(f1)\n","    results['auc'].append(auc)\n","    print(f\"Run {i+1} - Accuracy: {accuracy:.8f}, Recall: {recall:.8f}, Precision: {precision:.8f}, F1 Score: {f1:.8f}, AUC: {auc:.8f}\")\n","\n","# Compute average and standard deviation for each metric\n","average_metrics = {metric: np.mean(values) for metric, values in results.items()}\n","std_metrics = {metric: np.std(values) for metric, values in results.items()}\n","\n","print(\"\\nAverage Metrics:\")\n","for metric, value in average_metrics.items():\n","    print(f\"{metric.capitalize()}: {value:.8f} (std: {std_metrics[metric]:.8f})\")\n","\n","# Convert results to a pandas DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Save results to an Excel file\n","output_file = 'VGG19+LBP+SVM.xlsx'\n","results_df.to_excel(output_file, index_label='Run')\n","\n","print(f\"\\nMetrics results saved to '{output_file}'\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# VGG19 + LBP + XGBoost Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from xgboost import XGBClassifier\n","\n","def train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test):\n","    with strategy.scope():  \n","        y_train_cat = convert_one_hot_to_categorical(y_train)\n","        y_test_cat = convert_one_hot_to_categorical(y_test)\n","        \n","        model_FE_19 = model_vgg19()\n","        model_FE_19.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","        train_feature_19 = model_FE_19.predict(X_train)\n","        test_feature_19 = model_FE_19.predict(X_test)\n","        \n","        final_train = np.hstack((train_feature_19, train_feature_lbp))\n","        final_test = np.hstack((test_feature_19, test_feature_lbp))\n","\n","        # Define and train XGB Classifier\n","        xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n","        xgb.fit(final_train, y_train_cat)\n","        test_pred = xgb.predict(final_test)\n","        test_pred_proba = xgb.predict_proba(final_test)\n","\n","        # Calculate evaluation metrics\n","        accuracy = accuracy_score(y_test_cat, test_pred)\n","        recall = recall_score(y_test_cat, test_pred, average='weighted')\n","        precision = precision_score(y_test_cat, test_pred, average='weighted')\n","        f1 = f1_score(y_test_cat, test_pred, average='weighted')\n","        auc = roc_auc_score(y_test_cat, test_pred_proba, multi_class='ovr', average='weighted')\n","\n","        return accuracy, recall, precision, f1, auc\n","\n","# Perform multiple runs and store the results\n","num_runs = 10\n","results = {'accuracy': [], 'recall': [], 'precision': [], 'f1': [], 'auc': []}\n","\n","for i in range(num_runs):\n","    accuracy, recall, precision, f1, auc = train_fuse_and_evaluate_model(X_train, y_train, X_test, y_test)\n","    results['accuracy'].append(accuracy)\n","    results['recall'].append(recall)\n","    results['precision'].append(precision)\n","    results['f1'].append(f1)\n","    results['auc'].append(auc)\n","    print(f\"Run {i+1} - Accuracy: {accuracy:.8f}, Recall: {recall:.8f}, Precision: {precision:.8f}, F1 Score: {f1:.8f}, AUC: {auc:.8f}\")\n","\n","# Compute average and standard deviation for each metric\n","average_metrics = {metric: np.mean(values) for metric, values in results.items()}\n","std_metrics = {metric: np.std(values) for metric, values in results.items()}\n","\n","print(\"\\nAverage Metrics:\")\n","for metric, value in average_metrics.items():\n","    print(f\"{metric.capitalize()}: {value:.8f} (std: {std_metrics[metric]:.8f})\")\n","\n","# Convert results to a pandas DataFrame\n","results_df = pd.DataFrame(results)\n","\n","# Save results to an Excel file\n","output_file = 'VGG19+LBP+XGB.xlsx'\n","results_df.to_excel(output_file, index_label='Run')\n","\n","print(f\"\\nMetrics results saved to '{output_file}'\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5316766,"sourceId":8835279,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
